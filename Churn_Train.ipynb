{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99598135"
   },
   "source": [
    "# Descarga y carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "587c396c",
    "outputId": "0b1df70a-5229-4a34-a393-186614198d2a"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"blastchar/telco-customer-churn\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "e6bdc18a",
    "outputId": "a85e096e-3ec6-4ffa-9786-c15c4d2d31f8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path + \"/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6a9e625"
   },
   "source": [
    "# Dimensiones, estadísticas y tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dcb6b45",
    "outputId": "b294e896-ab57-4cad-ebf0-aec99d89de90"
   },
   "outputs": [],
   "source": [
    "# Número de muestras y variables\n",
    "print(\"Número de muestras:\", df.shape[0])\n",
    "print(\"Número de variables:\", df.shape[1])\n",
    "\n",
    "# Verificar datos faltantes\n",
    "print(\"\\nDatos faltantes por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Tipos de datos de cada variable\n",
    "print(\"\\nTipos de datos por columna:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77c7b9e7",
    "outputId": "c0b37c0c-fdfd-451c-c41c-52539d9ca573"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "210f8e03",
    "outputId": "0dc725d7-4acf-4988-e692-68f3f4da12ea"
   },
   "outputs": [],
   "source": [
    "# Seleccionar columnas numéricas\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Mostrar estadísticas descriptivas para las variables numéricas\n",
    "print(\"Estadísticas descriptivas de variables numéricas:\")\n",
    "display(df[numeric_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "345f4690"
   },
   "source": [
    "# Variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "176c935e",
    "outputId": "10c846d1-7adc-4aa8-9f02-ac32c03f5635"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear un gráfico de conteo para la variable Churn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='Churn')\n",
    "plt.title('Distribución de Churn')\n",
    "plt.xlabel('Churn')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwLLw2qy2Ikz",
    "outputId": "6417ff56-42cb-41b3-e811-ea1885be7431"
   },
   "outputs": [],
   "source": [
    "ratio = (df['Churn'] == 'No').sum() / (df['Churn'] == 'Yes').sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86704222"
   },
   "source": [
    "# Variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "16311884",
    "outputId": "ac8a0fdf-38dd-486a-c3c3-e5ae9f8440cb"
   },
   "outputs": [],
   "source": [
    "# Código de la celda 79b651a6\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# Seleccionar columnas categóricas (excluyendo customerID si no es relevante para la distribución)\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "if 'customerID' in categorical_cols:\n",
    "    categorical_cols.remove('customerID') # customerID is likely just an identifier\n",
    "if 'Churn' in categorical_cols:\n",
    "    categorical_cols.remove('Churn') # Churn is the target variable, will be visualized separately\n",
    "if 'TotalCharges' in categorical_cols: # Exclude TotalCharges as it was converted to numeric\n",
    "    categorical_cols.remove('TotalCharges')\n",
    "\n",
    "\n",
    "# Calcular el número de filas y columnas para la cuadrícula\n",
    "n_cols = 3  # Puedes ajustar el número de columnas según prefieras\n",
    "n_rows = math.ceil(len(categorical_cols) / n_cols)\n",
    "\n",
    "# Crear la figura y los subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))\n",
    "axes = axes.flatten() # Aplanar la matriz de ejes para facilitar la iteración\n",
    "\n",
    "# Crear gráficos de barras para las columnas categóricas en la cuadrícula\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    sns.countplot(data=df, x=col, order=df[col].value_counts().index, palette='viridis', ax=axes[i], hue=col, legend=False) # Addressed FutureWarning\n",
    "    axes[i].set_title(f'Distribución de {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frecuencia')\n",
    "    axes[i].tick_params(axis='x', rotation=45, labelrotation=45) # Corrected keyword to labelrotation\n",
    "\n",
    "\n",
    "# Ocultar los subplots vacíos si los hay\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIcqbDzUXM34"
   },
   "source": [
    "## Columna 'TotalCharges'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwMs-XC8XTSG"
   },
   "source": [
    "Esta columna se trata de manera especial ya que la mayoría de sus datos son numericos, solo hay uno el cual es un string vacío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd4nAj2zHMET",
    "outputId": "4ab8c3b9-0cba-4cf0-b1e3-02d7cc7aeccd"
   },
   "outputs": [],
   "source": [
    "# Buscar valores no numericos en \"TotalCharges\"\n",
    "non_numeric_totalcharges = df[pd.to_numeric(df['TotalCharges'], errors='coerce').isna()]['TotalCharges'].unique()\n",
    "\n",
    "print(\"Non-numeric values in 'TotalCharges':\", non_numeric_totalcharges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88a1372b",
    "outputId": "fa6273de-6091-496d-cb6a-ef898d00a590"
   },
   "outputs": [],
   "source": [
    "# Comprobar si las demás columnas tienen al menos un valor convertible a numerico,\n",
    "# y si es el caso buscar los valores únicos no numéricos\n",
    "object_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "for col in object_cols:\n",
    "    if pd.to_numeric(df[col], errors='coerce').notna().any():\n",
    "        print(f\"La columna '{col}' tiene valores numericos y sus no numericos son:\")\n",
    "        print(df[pd.to_numeric(df[col], errors='coerce').isna()][col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "Y0IB8-qkY7jN",
    "outputId": "03569f43-860c-48dd-97e1-637e38d81f48"
   },
   "outputs": [],
   "source": [
    "# Filas con la columna \"TotalCharges\" vacía\n",
    "df[df[\"TotalCharges\"] == ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9jQEqb4kzOj"
   },
   "source": [
    "## Exploring how to compute TotalCharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfcb3hL4d1rR",
    "outputId": "c83ca21a-fb18-485d-907a-b6849c1b88f1"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "dMEfpnMdhw2M",
    "outputId": "a8464819-c1e0-42f0-ad9b-fcd7e346e50b"
   },
   "outputs": [],
   "source": [
    "df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gEVP_SZmb6sL",
    "outputId": "3cb3a293-695e-4f1b-8f13-4a78439124d3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 1000\n",
    "df_cols = df.loc[:n, [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]]\n",
    "\n",
    "# to numeric\n",
    "df_cols[\"TotalCharges\"] = pd.to_numeric(df_cols[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "computed_total = df.loc[:n, \"tenure\"] * df.loc[:n, \"MonthlyCharges\"]\n",
    "df_cols.loc[:, \"TotalChargesComputed\"] = computed_total\n",
    "df_cols.loc[:, \"LE\"] = np.where(df_cols[\"TotalChargesComputed\"] <= df_cols[\"TotalCharges\"], \"True\", \"False\")\n",
    "\n",
    "df_cols[\"err\"] = (df_cols[\"TotalCharges\"] - df_cols[\"TotalChargesComputed\"])**2\n",
    "df_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-yf-92CDra6",
    "outputId": "4609bcd3-f5e4-4045-9486-fc7dd8ac7dda"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "3G09TsXgiwYA",
    "outputId": "b74220c7-6af8-4220-870b-5a3f467e40d5"
   },
   "outputs": [],
   "source": [
    "plt.plot(df_cols[\"tenure\"], df_cols[\"err\"], 'o')\n",
    "plt.xlabel(\"Tenure\")\n",
    "plt.ylabel(\"err\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "EZPmp4cwlasA",
    "outputId": "eb6c191d-af35-4c00-8326-e91e667d445b"
   },
   "outputs": [],
   "source": [
    "nan_rows = df[pd.to_numeric(df['TotalCharges'], errors='coerce').isna()]\n",
    "nan_rows[[\"tenure\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\"]]\n",
    "# nan_rows.loc[488]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86cd6d52"
   },
   "source": [
    "# Variables numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "5d21d400",
    "outputId": "4d98ff43-1ea1-4bd8-d660-203e94e1e9e7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "nan_rows = df['TotalCharges'].isna()\n",
    "df.loc[nan_rows, 'TotalCharges'] = np.fmin(1, df.loc[nan_rows, 'tenure']) * df.loc[nan_rows, 'MonthlyCharges']\n",
    "\n",
    "# Seleccionar columnas numéricas\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Calcular el número de filas y columnas para la cuadrícula\n",
    "n_cols = 2  # Puedes ajustar el número de columnas según prefieras\n",
    "n_rows = math.ceil(len(numeric_cols) / n_cols)\n",
    "\n",
    "# Crear la figura y los subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 4))\n",
    "axes = axes.flatten() # Aplanar la matriz de ejes para facilitar la iteración\n",
    "\n",
    "# Crear histogramas para las columnas numéricas en la cuadrícula\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    sns.histplot(data=df, x=col, kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribución de {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frecuencia')\n",
    "\n",
    "# Ocultar los subplots vacíos si los hay\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWZaGsaZDJp_",
    "outputId": "07bed42c-ac82-4440-9b7f-764cdb0c1441"
   },
   "outputs": [],
   "source": [
    "numeric_cols = numeric_cols.drop(\"SeniorCitizen\")\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JCENiWPDUo8"
   },
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YewmzhDXDYwV",
    "outputId": "ad8eda95-8fae-413d-9653-4275916d363e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Drop 'customerID' as it's an identifier\n",
    "df_temp = df.drop('customerID', axis=1)\n",
    "\n",
    "# Encode target 'Churn' as 0/1\n",
    "le = LabelEncoder()\n",
    "y = pd.Series(\n",
    "    le.fit_transform(df_temp['Churn']),\n",
    "    name='Churn',\n",
    "    index=df_temp.index\n",
    ")\n",
    "target_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "\n",
    "# Drop target column from features\n",
    "X_temp = df_temp.drop('Churn', axis=1)\n",
    "\n",
    "# Separate numeric columns from non-numeric\n",
    "numeric_cols = X_temp.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_temp.columns.difference(numeric_cols)\n",
    "\n",
    "# --- Process numeric columns ---\n",
    "scaler = StandardScaler()\n",
    "X_numeric_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_temp[numeric_cols]),\n",
    "    columns=numeric_cols,\n",
    "    index=X_temp.index\n",
    ")\n",
    "\n",
    "# --- Process categorical columns ---\n",
    "binary_cols = []\n",
    "multi_cat_cols = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    n_unique = X_temp[col].nunique()\n",
    "    if n_unique == 2:\n",
    "        binary_cols.append(col)\n",
    "    elif n_unique >= 3:\n",
    "        multi_cat_cols.append(col)\n",
    "\n",
    "# Encode binary columns as 0/1 and store mappings\n",
    "X_binary = pd.DataFrame(index=X_temp.index)\n",
    "binary_mappings = {}\n",
    "\n",
    "for col in binary_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_binary[col] = le.fit_transform(X_temp[col])\n",
    "    binary_mappings[col] = dict(zip(le.classes_, range(len(le.classes_))))\n",
    "\n",
    "# One-hot encode multi-category columns\n",
    "X_multi_cat = pd.get_dummies(X_temp[multi_cat_cols], drop_first=True)\n",
    "\n",
    "# Combine all features\n",
    "X = pd.concat([X_numeric_scaled, X_binary, X_multi_cat], axis=1)\n",
    "print(target_mapping)\n",
    "binary_mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "rR31aVw7BzzG",
    "outputId": "70fd0fae-274a-49cd-9d60-b110c1237140"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0cbcCPUBmqC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdhwZ8Ds13AO"
   },
   "source": [
    "# Train LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0w7Y6-Vq24z3"
   },
   "source": [
    "## Use SBS to select best feature subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RZZguJu15fQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from itertools import combinations\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_sbs_logreg(X, y, min_features=1,\n",
    "                          C=1.0, max_iter=500, random_state=42):\n",
    "    \"\"\"\n",
    "    Sequential Backward Selection (SBS) with Logistic Regression.\n",
    "    Stores only the best subset at each step. Assumes features are already scaled.\n",
    "\n",
    "    Returns:\n",
    "        best_model      : trained LogisticRegression on the best feature subset\n",
    "        results_df      : DataFrame with best subsets per step and their CV recall\n",
    "        best_features   : list of feature names in the best subset\n",
    "    \"\"\"\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "\n",
    "    feature_names = X.columns.tolist()\n",
    "    current_features = list(range(X.shape[1]))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    results = []\n",
    "\n",
    "    while len(current_features) > min_features:\n",
    "        subsets = list(combinations(current_features, len(current_features) - 1))\n",
    "        best_score = -np.inf\n",
    "        best_subset = None\n",
    "\n",
    "        # Evaluate each subset\n",
    "        for subset in tqdm(subsets, desc=f\"SBS step: {len(current_features)}→{len(current_features)-1}\"):\n",
    "            subset_list = list(subset)\n",
    "            X_subset = X.iloc[:, subset_list]\n",
    "            # X_resampled, y_resampled = apply_smote(X_subset, y)\n",
    "            model = LogisticRegression(C=C, max_iter=max_iter, solver='lbfgs')\n",
    "            score = cross_val_score(model, X_subset, y, cv=skf, scoring='recall').mean()\n",
    "\n",
    "            # Keep only the best subset for this step\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_subset = subset_list\n",
    "\n",
    "        # Append the best subset of this step\n",
    "        results.append({\n",
    "            \"n_features\": len(best_subset),\n",
    "            \"features_idx\": best_subset,\n",
    "            \"features\": [feature_names[i] for i in best_subset],\n",
    "            \"cv_recall\": best_score\n",
    "        })\n",
    "\n",
    "        # Use best subset for next iteration\n",
    "        current_features = best_subset\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Pick overall best subset\n",
    "    best_row_idx = results_df['cv_recall'].idxmax()\n",
    "    best_features = results_df.loc[best_row_idx, 'features']\n",
    "    best_feature_indices = results_df.loc[best_row_idx, 'features_idx']\n",
    "\n",
    "    # Train final model on best subset\n",
    "    X_best = X.iloc[:, best_feature_indices]\n",
    "    best_model = LogisticRegression(C=C, max_iter=max_iter, solver='lbfgs')\n",
    "    best_model.fit(X_best, y)\n",
    "\n",
    "    return best_model, results_df, list(best_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945,
     "referenced_widgets": [
      "1a0e89ed9f6d451d9506bcaa06c5e88f",
      "f4dce5f0a2b24da1bb699c0edfd4531a",
      "dfa3dc04463246b09a538cf399fa916b",
      "c8769e746c054a4fa9aede71a460f78b",
      "73133218c1324cb19c961c0e147f0668",
      "98adcf8270b34eabace1a76d1107bf62",
      "25dae5d174b241c6a2151777a6d64017",
      "f4ec42a5418a4bee8c62428b0232ed13",
      "44c804b16b6e44cd9a8635d2e729dc96",
      "b2afeea6a98e4377a3538a035f7c8e05",
      "a14ebe8b68164c5b9114974b2d3a7203",
      "759481ffc3744c2a90c91f9a8764038c",
      "8dacc991777f467fb061eaa6d52b10eb",
      "a3ba230b2aa24051aabbd6b25e965e22",
      "3855c97b522448de83d3421ba4a74e6e",
      "6b012057e5bb4d478a32cec2dd40706a",
      "e84094a8799d4fa1a2f534fa1c1cdd7a",
      "75ada12b15ec4ef4ab82a0434f80a8dc",
      "8499d28b2d8240f3b5763693d1fd91dd",
      "e5523dbcc2ea4cd98e77f610acc01e40",
      "e2c29beb91d141f29e430ea5b08fd2f5",
      "768ae8b7410947d79f0c015928482678",
      "f249411c6fba45fe8eeac7360cd1ffa1",
      "464d6611415d4efd8b0adc8008736a00",
      "2a5b6d2995924a08b63b7f7ab9c6b883",
      "435ff2c054c949799fa2a76052c94465",
      "cc04a973b124424798d19b5e4d5c844b",
      "7803474ecfcb415ca79ddd08294a3592",
      "f06dbc6323284fc6a814b30481bf6a0a",
      "111d8c9a0b244507879355b322bd3a11",
      "9b7b9e6d17fe493c97df5f18963342f9",
      "b0743d01ad464753932adfb8a18e34fc",
      "049fee19c8f94c608991e35c407acb21",
      "5b7d77d52b2b428e95849a18df8d4bcf",
      "279ffe268ced4070b4fa1d1f30485dcd",
      "67e7069e80a64383b84f308aabd15c2b",
      "3a2488e8b09b4fdd9d5900906995f3ca",
      "e0098d577c5d4e719ab1d97298fef79e",
      "34e34c2d80a446a98bbfb52bcac624cd",
      "f5c7def6c8dd43f086e9f790bf30794d",
      "fd9ea2a59e6640b5a324992ac44356f4",
      "1eec94a6c70044808c149512feebd9ea",
      "f1b634f21b3640b4b391f62af91fb5e3",
      "caad72f6fb2b45a28d58990b6803fd6c",
      "f79e5e95736e42ec9e43105480f2b72c",
      "36b40ec77db544a986980be032d0c6a4",
      "6630a760ca134b91ab066abb6237cbc7",
      "1457add65da44ca0882f56742655f39e",
      "2b3dbd97fe1d417db6910475c55f4c84",
      "10cb1709663f457985331fe5c3f6effe",
      "4af8b3f4cb894879bc5a2a5180854c4f",
      "23e39c0cf3c84f80b99eee301789cdff",
      "fc8500bd79334a4bb67a46fd89921fa0",
      "716d4e56f76f45d081b60665d07769dd",
      "88c0faeb43144d99a132985ac4eda1ac",
      "61048f4f561b483888010b8c2358f208",
      "711aa4e1ece549eb85368a4060015805",
      "783b0b277907432da100f20ad67ad121",
      "8a0a03b309ac4587a9f10be65e194217",
      "2609f4a4c7bb4fdc833883fbe4867cfe",
      "9bf43b9bab844e2b86e05b48d9b3f985",
      "791220f13c144950963e0f1a8935a02c",
      "5d570ad4ebc84d628ef82d9d2860d066",
      "e8c83a6534394d809f5a0869934ad56d",
      "5dfd5692bf8342799e6d7f920a8ad953",
      "22e0ac1a50684f1f8f9143cfb6e1b846",
      "f2d8bac38daa47a9b37d88c06072ddd8",
      "287460d7d401440f9e21a34aebbb0848",
      "f45053bfc5b2479fb55c4a9a265f75ca",
      "9ff498f1af364698867e7532ffa51a99",
      "2f47ea8d73a5455fbd422c024b16c90b",
      "50d516a9fa934799b31f555ce9122907",
      "328fe051c0f64b9897940b8b8607c345",
      "1e38660f014d4f99afcc8f78a2528490",
      "10199880f50849d4be84f10195ef7b87",
      "004b4a33f2af41a98e749fac914fb302",
      "d7655b69d1774201b720fa9c24538ddc",
      "08f3ebc7fac745319842c9a108cc7d99",
      "a7dfdd92cc12442ea11f85acc8c42cb9",
      "64be5390a8d34e6aa228e2ba47571145",
      "90ab91f7a37b45a6aaf0bf8a427a30ce",
      "7ddcf55e2d9f4b26948f01621e104adf",
      "e8d3398d4f5e4131accc1bae25f1db45",
      "26ea0b0607a04c46a688d81c3de2e032",
      "cabcd7a28a714195af6aef89276278a0",
      "5e421f4bf92146f4b9101165eed6830b",
      "3d680d871d94404e918ef3c6341df87d",
      "e03db462a17f4692871200a5ad9a9b3f",
      "83a94ea2877c47c1b1822f77236c7ef9",
      "7316c8b88a854b76950ca08e164b7640",
      "b46ddeecb1c04f3d9e94483d6b6c0e96",
      "702bc6e3915b4376b9bf032345d0db36",
      "2a5e38ed58db4eb9847cc0f591c479b5",
      "50e8d4dcafbb43418b0477f16b62789e",
      "9a884013f04c4059ace7a6f9d3b5ed2f",
      "841d6a00d9244867a8d9f9dac655bfee",
      "e29bd2e3eb384102ac464cc5ec2f0f7a",
      "876eeb3bd5c142ea8f3271fc45ac9a7d",
      "c1b1386d335d4c2d8a760d75876b8f5e",
      "3b3e3200940648469521e3caee1e08e4",
      "138ff0b321d6465fb5acbcf6f1fecf2f",
      "1fc4974560a741a7a56ec116f1ed419c",
      "451e71f4f912435e930f9fba0ccf503c",
      "2070e9430c934690b85e55bb1898303b",
      "357e13aabc4d4f8ca8d465dd57106650",
      "bacf6475977543cbb1d6d80056e2b9eb",
      "872f7e421ce0443a9835ace6abfe06f2",
      "4b392319677e4ccf96d6c2b3d94b633f",
      "2cf692112e934a3b80290a823f3d1bbe",
      "85dd55cfb7014b68be26a06d8e600b9b",
      "9593b744a7fb4342a5a4dbfa3f02d870",
      "eb5482ff60594ef798573e631fe32836",
      "dba7d7fdbd2847f4838abdbb6862195a",
      "a3fe592f5b8e4dc0aace77605ffe25c7",
      "c8b50442e397464caff51d6d68cd9858",
      "493187180a6e41159d1ecbf69db5c3b1",
      "828d70cf56e5400eb5484ef1d8106f19",
      "141caf4e593647c4ba3a1c32b658b1c8",
      "b7edc824cf3a416bbebf12557c2e70b8",
      "3864ee96c91046eb8c23f711d9ea03b4",
      "aa622cc1dbd84531820cf5d7eef3f6b6",
      "8219cb186d8b4cf3ba0161cfc4c09c27",
      "32fbfc58dbf94bc09658fcb1203c7ec2",
      "e6ff6bf0ed1a43a8ad7ede2ce9b14527",
      "8d5aedc9bc5e47c5b5f2dcb10ef1657b",
      "d68846d3ce9f4c338de58593d80b782d",
      "3f6fade7db7746d292edfc7bff83ce37",
      "4731a0c704fa4a6ca436db958ce50fec",
      "e1ff85424d2047bf82a4b226fdb57a65",
      "cdbef68141524b518844956cfad6a89d",
      "c5a8d138fdc148718d029f274cc47a60",
      "0a07abba362343c3931703196f27c1ce",
      "0880930333134eea94aa717da4fd0bfa",
      "b3828021d08d4f35a2d1ecbadebe06b4",
      "2ff2ae71580c49068ac5d24af61cd33d",
      "866dc37ef0d04430add6d9833883a27f",
      "630735bb892441d2a10c016580c6bd7e",
      "106c56b6b2a745acbad6fd41c2abe12e",
      "c8363756ffa24ee8bf655a4a9e4ab6ac",
      "d767b46eff444720b5dfd395044f4243",
      "ed966f3c8f744327a75e9c21be0b9e01",
      "0364d2660e694365832367f6c7e1d461",
      "f94b2535d35c4c96be270d5c12e6945e",
      "f4f5a34ee4164f909738e7d092ac64fe",
      "fa2f5ad5afd04732849b2a43bd6b149d",
      "74680b3b849e4f2c9a026b5b8a3cb35c",
      "be7361dae523482abaf01442cccb676b",
      "8897119e64944621b805e1a31d62050c",
      "c17a47e02d3f4015a0026ff7bc964e21",
      "8785465412064cacb91f4ee6f60422fa",
      "28b9f11aaacc4c1da14f6cb3504cc619",
      "c7e9bd22ad6c437cb4660da676243b88",
      "cf623cc7c44c47e0a53a29bc29969c71",
      "0e01ceac21a5484d897fee05aa659421",
      "4d7e05c832964122a300504635126f58",
      "c41c0300231f4cceb6f9969dc5078c29",
      "5459b1bee59b459e85da3e8b7599ac8a",
      "085d250be25048fc90b54e4b8e12d0fd",
      "75f7b2682c924f61bb6483d8a2b646ab",
      "fc5af596ed2449988906d2ef95fa3416",
      "06763e9ddb3f45998067af53efdfee5f",
      "6163223384844ce1bd67c1794750a7a3",
      "3141a61934a043a98180039810f93f8e",
      "20f56143d4334f488fe89ea210bc00cc",
      "79dd174553ca4515af4cb483d2d94490",
      "3d40c30ad56a4fa7ac202ec94ced7a9a",
      "318d6f29eaa74723822268d9598e05f0",
      "1601725afc9f424da5491f9587c4e4af",
      "c84b1a2ff6344ffdb6eef55e30303cca",
      "27142d02bd1b4ac09563351148bd023f",
      "3b3771347f4e47ef97f339c20d493745",
      "141a77cd95d94a7c95e43a99c0466c52",
      "339da5fda7a1487cb2b06893843012f1",
      "35f2218971f34179bf5e451ecd6dac7f",
      "8402f58051ca416a8dd89294dacac9e5",
      "2d84d1eeff3e47339c2fd9cea2432d39",
      "13118f14b2e14438a1fca3a5dba53ff2",
      "8899141daddd4fb5af67033d19b5acfe",
      "8008c99404b24d3687ade49104e0f871",
      "55b7545b2d93480cb9d1d8d80a651286",
      "1e019ebc7e0046c2bc0266c8e76b9f82",
      "66fcc15ccb8b4be48863240a380ef7ac",
      "0c7ca71b47204507a20d429b4617adc6",
      "61db62090ca0433994593959a4b14e88",
      "38d12cc88dce4d49bdd5c9298c317782",
      "7ca0f858f7ba40fcbd9e2107fd385117",
      "5038fc0ab7194ca8a7632758bff06d1f",
      "54e17309b6ae4d11a3948026c1f71500",
      "02f350e3713c46d6ac13a9d1195d2056",
      "e8b996b886b0416e8bb2025878967358",
      "8b3c6dc6661745809fccbb0446c2fc0c",
      "cfff0ebad41344d88672bdb148ff51a5",
      "adae1ff72c7747c9ab7cf94e66d317f7",
      "4a87ffc796074d189049c2f3259b1b7f",
      "c8e0a1736c84492ebfad83f87dce0ca0",
      "c600b76c65914881bc01e84011cb7b03",
      "f5186accbeb644db9ba85305760fa4c6",
      "e375c850b64844dfbb870e66b9111a96",
      "4fb69c51c21044d48e159eac4cb4a993",
      "7a85f77dbd0d4b44b23c45f91e5224cb",
      "d5b201baf4b346f6941315e1fcb735b5",
      "13ace2a5a45f4143bb103222af88a8c6",
      "a52aaa5aa3d5493c805aa92d5c9e9804",
      "b752bfe835124d288d229a175b76ebbd",
      "4a49455ce7744270b112701f4a2a2bf4",
      "9d7fa208757241888ab226ad32d86381",
      "81d2e32e13a44966a5e213a6d274b189",
      "e757152a645d4337b43720f6815cbe0d",
      "23a6c52a0e3640da886e84e146868f87",
      "ace823737e8e4450983e20f9343b93a2",
      "6311cc16ed0d414cbabf80bdec8f9121",
      "9b29c992065648ceac20a26c9bff05f0",
      "c3e06a3b3c25436881573d812b804bbc",
      "7bfb0b76cd0245e9964a5dc87e82bc21",
      "7bf8f6c84f6f4da185438b02960bd521",
      "dc880c4f04e64d7d8dcaecc2789820f5",
      "f21e03646f1540b6a555fa770cc96095",
      "9d4b07963bdb4c58aa076cc744f7d210",
      "7868dca8fd4449d5a3fd0edb30d89f3e",
      "110f2797f3df4c7ca7fce396da8076a1",
      "d2c4456d9fe243c4aecbb3125c98d7c2",
      "be1c1bc2b53e41648ef4ee8deb23b4fc",
      "4e2e049cb850445c869d73d473d9762d",
      "926097cef9e940a8bc12aaef90c5a008",
      "f9c217b84b2641df8d2fe86e5060f4aa",
      "fd43578429af404bb56f29b35fd9bf97",
      "585a1e40187149b89a192e938033d83b",
      "659c63ea7c014a578ce7abd95289b3d5",
      "8eeeb71a88ba4597b9b2989f3c9a935e",
      "1fbae097c5a44705a9811a3d082e0c10",
      "76ef02ff575747d09734c39883208c1d",
      "575f5aebd19945f6b49e71a2e353c5f7",
      "7370f58871404f54b5edfc0b49f4f929",
      "b4f36418663c49fa9f67592f0676c817",
      "d9ee4e26c3264dfe88652dd3f6599177",
      "167f8dbeb84f4fd5a311310f230ffcd6",
      "67a07f150a354284a5657e2a576fb45b",
      "b75f549dbf9c4d7fbef9533cd9277db1",
      "afd4db80dd194d0f9b181f812dbe9291",
      "fcb233e4903144aea2986fc67235a8a2",
      "72446ccf7dd94dc4b4da5e6c4b303b97",
      "ccb524b084d040fc8b5f6b5201f89a58",
      "080c4b6d5381465d9478a4d381d58ffc",
      "e17fa5aaef0b40049c9ee643d277667b",
      "a7ced607e5b149bb846411a0f4a501c0",
      "2cc87fe73a3d43d7859ff4b73a3fe373",
      "24f2079db74b40e0b633e123e9a83a92",
      "b7fbffcdf98e4a42b777b1bdb62da9ec",
      "702d17e6ce1c4b07ad970d96082f2a08",
      "76146901475943088132c44f7353873e",
      "bf6145023f0040fcafc6d534a6059bef",
      "2b62d58c902f4cacbf86cf3480ea4cf3",
      "404a2e0dea41466fb1229daa6b6f47a1",
      "2377d21e4e5c4639a021890fd3bfb827",
      "3887ed87a4c04601b53951d56a1f3000",
      "875eb9ed98314d38a669d678a53abf33",
      "b59c0b78bab64d0696708813cc768f93",
      "7998d92d601c4ee2b38ce55e4f7423f2",
      "06dff64b2f534956817d2722f5c22d57",
      "a50c857d742943ecb8fc5cc243a0b6c1",
      "312cf7ead22a4a9e81c10a60c3646eaa",
      "7dd0d1852deb4c6abe8e5655b653829a",
      "0f0ab7a575234ef0af4beffe1d6214fb",
      "5fef3953e3e54f2d9b77b92dcb7e7c72",
      "49f12f071e6f4b9f8103eb0197e9342a",
      "ba9bbbc9a86444a0a51b319098009f6f",
      "3f035fbf52e944e299a91520c12d8912",
      "0c1eaba6789a4fd6a6dc0705a3c8e87d",
      "a9ff60f57eb54ac38f1f676d88115466",
      "7a815113705143bb8f0adbfc41126dea",
      "8785b61cc9c34edfa513e3ba0941b3c2",
      "30f1ff2efbf141a383c799b78e48f931",
      "27e5a9b647f14f6e904fc39055fd9213",
      "5e54954ffd134988b65623b6d64c8c80",
      "917fab4d72be455d883c6f377fecc5fe",
      "73ea34b77e0d437a98428ebd85948234",
      "bb30b280f3c6435885a26e3cac8c4ce6",
      "816d5c828bf842acb19427f5e866d941",
      "c14e540ece184e80aa8bb224c09f1575",
      "703c2e6005eb48fba100185ce4ad8de9",
      "51f474c685c3462f9d37bfc6702c7f86",
      "05d88f60b3a548409774b43cc7c6f9c1",
      "d4dea53d4f3246d99fd65584375bc661",
      "b0d0aa87a5b44f0390d00c69acb16c44",
      "b1dab3d038a0480988ad2079e4aa3fa5",
      "1aca3896213844b8a573fdbde2a153f2",
      "960c30b875474411b63883ef08d414fc",
      "ff5097834f664e99a9a88b1bd43cca02",
      "14155355fb3645848dd905e373738075",
      "71278a59f15a49b682c43b6cc9384fcb",
      "f13aa2c7b52c411397f6ebaa9894a8d6",
      "1ce47a48775d474fbc27ce8c4ee204fa",
      "f75f9eee969e48c38c64616a8ecfde06",
      "57cdcca6124345c486dd45b0e49c6588",
      "8ad9964a77a246a2a4e47bbc4129058c",
      "4cd925d11b884ddea4d6983c294af75a",
      "9a66ad7131444a3993fbfa8308dac3e1",
      "cc0828a5a8394ef69dfc73924d866f9d",
      "bc525a4847ad4bdc859ed6e166d16d75",
      "02a310628de0428fbd2e4267c70cce70",
      "abeee8db18f44775b866f08b8c4818b2",
      "c6d6eabddfae4d1c9f09fae7d683c6fb",
      "5f2223fe62a2418eac50f83f278407d7",
      "29ad67909d6d4a0f8973a64ffbdfd180",
      "05fb75efd30b4397b06b7433ffaadbde",
      "cf722b8605724531a4b4f4e745498b09",
      "da3e2ef2564741b28e44abe4483d9292",
      "3215f9bcff73403485593bbc38fbe1ec",
      "6a3c900654b744198947637f21b79133",
      "c04471383858417bad49713b431a9a51",
      "36ef27ef2102401f89e789e5b5085b9c",
      "76c5a2a96e4a405f8dc792690084b068",
      "760e77986b5c4e72a0e4814a222b3668",
      "847e0a232d45478bad954a787ac6589d",
      "56dacccaef6345f5b32220007f27b5b8",
      "d0a99f15fac94b5385bcaff7938702c8",
      "47e4c8949f2141c1b01b3b8b27eb9248",
      "8a68ed2fe9284ab5a8f5ece4dbd1c2e0",
      "3cb6c6c42afb42e4bc0b2dcc8322c06b"
     ]
    },
    "id": "92WlE-sf2gYA",
    "outputId": "84f00c8f-d594-4670-a479-1a8df15f8343"
   },
   "outputs": [],
   "source": [
    "modelLR, df_results, selected_features = train_sbs_logreg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZWN88J-BN6x",
    "outputId": "8a8ac7b4-6bc7-4453-d55f-822873959118"
   },
   "outputs": [],
   "source": [
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wit2E0nkM3gp"
   },
   "source": [
    "## Some plot utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhWBeTE72-pF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "def plot_sbs_scores(results_df, highlight_best=True):\n",
    "    \"\"\"\n",
    "    Plots CV recall vs number of features from SBS results.\n",
    "\n",
    "    Args:\n",
    "        results_df (pd.DataFrame): Must have columns ['n_features', 'cv_recall', 'features']\n",
    "        highlight_best (bool): If True, marks the subset with max CV recall\n",
    "    \"\"\"\n",
    "    # Sort by number of features for nicer plotting\n",
    "    results_df_sorted = results_df.sort_values('n_features', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results_df_sorted['n_features'], results_df_sorted['cv_recall'], marker='o')\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"CV Recall\")\n",
    "    plt.title(\"Sequential Backward Selection - CV Recall\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    if highlight_best:\n",
    "        # Highlight the best subset\n",
    "        best_idx = results_df_sorted['cv_recall'].idxmax()\n",
    "        best_n = results_df_sorted.loc[best_idx, 'n_features']\n",
    "        best_score = results_df_sorted.loc[best_idx, 'cv_recall']\n",
    "        plt.scatter(best_n, best_score, color='red', s=100, zorder=5)\n",
    "        plt.text(best_n, best_score + 0.002, f\"{best_score:.4f}\", color='red', fontsize=12)\n",
    "\n",
    "    plt.gca().invert_xaxis()  # optional: show decreasing number of features from left to right\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Mwgro_hM92v"
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "C8jP0wBhI5Ea",
    "outputId": "fcd9f425-2470-494b-ac35-05de42e534d0"
   },
   "outputs": [],
   "source": [
    "print(len(selected_features), \"features selected:\", selected_features, \"\\n\")\n",
    "plot_sbs_scores(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rnzA_UjPJGL",
    "outputId": "08382880-7c6c-4cdf-be7a-06f616ce7191"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Report for training:\\n\", classification_report(y_train, modelLR.predict(X_train[selected_features])))\n",
    "print(\"Report for test:\\n\", classification_report(y_test, modelLR.predict(X_test[selected_features])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "id": "7QvAQj0QMaH9",
    "outputId": "78cc5760-8362-49d7-c568-56ebcf7a4a2c"
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(modelLR, X_train[selected_features], y_train, cmap='Blues', normalize='true')\n",
    "ConfusionMatrixDisplay.from_estimator(modelLR, X_test[selected_features], y_test, cmap='Blues', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "id": "--Cl04wpay6r",
    "outputId": "4bc6023b-1336-4c16-892c-7a8373f87313"
   },
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(modelLR, X_train[selected_features], y_train)\n",
    "RocCurveDisplay.from_estimator(modelLR, X_test[selected_features], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jvvHojt2wEy"
   },
   "source": [
    "# Train RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1X2fKoQA2vSr"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "\n",
    "def train_random_forest(X_train, y_train, X_test, y_test, random_state=42):\n",
    "    \"\"\"\n",
    "    Entrena un RandomForestClassifier con GridSearchCV y calcula recall.\n",
    "    Retorna el mejor modelo y sus métricas.\n",
    "    \"\"\"\n",
    "\n",
    "    # Definir espacio de hiperparámetros\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [10, 20, 50],\n",
    "        \"max_depth\": [None, 5, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1, random_state=random_state)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        rf,\n",
    "        param_grid,\n",
    "        scoring=\"recall\",\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # Predicciones\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Métricas\n",
    "    train_rec = recall_score(y_train, y_train_pred)\n",
    "    test_rec  = recall_score(y_test, y_test_pred)\n",
    "\n",
    "    return best_model, train_rec, test_rec, grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NbSg4qZ20Lx",
    "outputId": "029c084c-b75f-4098-cb09-fdda93b4db45"
   },
   "outputs": [],
   "source": [
    "modelRF, train_rec, test_rec, gridRF = train_random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OOIKGI4CyIZ",
    "outputId": "e5243b9d-3fd2-4ee1-d5ad-9d7fd5e1518b"
   },
   "outputs": [],
   "source": [
    "print(f\"Train recall: {train_rec:.3f}, Test recall: {test_rec:.3f}\")\n",
    "print(gridRF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-SvZJxmQMZG",
    "outputId": "814fe558-b266-4bde-bc30-ae28dfccba79"
   },
   "outputs": [],
   "source": [
    "print(\"Report for training:\", classification_report(y_train, modelRF.predict(X_train)))\n",
    "print(\"Report for test:\", classification_report(y_test, modelRF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "qTmc2QQaCR2B",
    "outputId": "f63ba2ca-aebd-4f7a-cceb-8727441ad72a"
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(modelRF, X_train, y_train, cmap='Blues', normalize='true')\n",
    "ConfusionMatrixDisplay.from_estimator(modelRF, X_test, y_test, cmap='Blues', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "id": "KY-vwmqtCA-c",
    "outputId": "04a70890-b404-4a32-92f9-8a95dec6ce26"
   },
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(modelRF, X_train, y_train)\n",
    "RocCurveDisplay.from_estimator(modelRF, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbj6IAkKOdXN"
   },
   "source": [
    "# Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbMQLwAN-gs1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class TQDMGridSearch(GridSearchCV):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        # total combinations\n",
    "        self._param_combos = list(ParameterGrid(self.param_grid))\n",
    "        self._pbar = tqdm(total=len(self._param_combos), desc=\"GridSearch\")\n",
    "\n",
    "        # wrap the parent fit\n",
    "        return super().fit(X, y, **fit_params)\n",
    "\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        \"\"\"Override to include tqdm bar\"\"\"\n",
    "        for params in self._param_combos:\n",
    "            evaluate_candidates([params])\n",
    "            self._pbar.update(1)\n",
    "\n",
    "        self._pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBH6XzDLPA0y"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def train_xgboost_with_tqdm(X_train, y_train, X_test, y_test,\n",
    "                            n_estimators=None, learning_rate=None,\n",
    "                            max_depth=None, random_state=42,\n",
    "                            param_grid=None, cv=4, scoring='recall'):\n",
    "  \"\"\"\n",
    "  Train an XGBClassifier using GridSearchCV (preserving original function name).\n",
    "  Focuses on minority class recall for imbalanced data.\n",
    "  \"\"\"\n",
    "  if param_grid is None:\n",
    "    param_grid = {\n",
    "    'n_estimators': [n_estimators or 100, 300, 500],\n",
    "    'learning_rate': [learning_rate or 0.1, 0.05, 0.2],\n",
    "    'max_depth': [max_depth or 3, 4, 5]\n",
    "    }\n",
    "\n",
    "  scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "  model = XGBClassifier(\n",
    "      random_state=random_state,\n",
    "      eval_metric='logloss',\n",
    "      scale_pos_weight=scale_pos_weight\n",
    "  )\n",
    "\n",
    "  grid = TQDMGridSearch(\n",
    "      estimator=model,\n",
    "      param_grid=param_grid,\n",
    "      scoring=scoring,\n",
    "      cv=cv,\n",
    "      verbose=1,\n",
    "      n_jobs=-1\n",
    "  )\n",
    "\n",
    "  grid.fit(X_train, y_train)\n",
    "  best_model = grid.best_estimator_\n",
    "\n",
    "  # Predict with custom threshold\n",
    "  y_train_pred = best_model.predict(X_train)\n",
    "  y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "  train_recall = recall_score(y_train, y_train_pred)\n",
    "  test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "  return best_model, train_recall, test_recall, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e02bbed1cc4245d8ba79df2359a58779",
      "77f9f52681a14c7184de2e5ff179cc43",
      "0ff71247553e4937885f3b7b21c44d23",
      "789088009cd444afb17627f14320fce1",
      "5a59c12e6cc542dc882ecacfc3129168",
      "4a05e5d81d964a00a9967732c96e9eb7",
      "7a6fd1e55c16417bb88994014f5ae244",
      "2005dd13ff4044918b1148f5904b2437",
      "f85576631f8b4757a3778034968cbcf5",
      "861c124018ee4456b39af74f8578a7ad",
      "550e5e8a1f824f4eae5bed511f7e90dc"
     ]
    },
    "id": "J5td4rhFPCHa",
    "outputId": "b413674b-e1c8-45fb-b4d6-07508622380f"
   },
   "outputs": [],
   "source": [
    "modelXGB, train_recall, test_recall, gridxgb = train_xgboost_with_tqdm(X_train, y_train, X_test, y_test, param_grid={\n",
    "    \"n_estimators\": [2, 4, 5, 10],\n",
    "    \"learning_rate\": [0.0001, 0.0002, 0.001, 0.02, 0.03],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"gamma\": [0.0001, 0.001, 0.01],\n",
    "}\n",
    ")\n",
    "print(f\"Train recall: {train_recall:.3f}, Test recall: {test_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0QVksqsb3yi"
   },
   "outputs": [],
   "source": [
    "print(\"Report for training:\", classification_report(y_train, modelXGB.predict(X_train)))\n",
    "print(\"Report for test:\", classification_report(y_test, modelXGB.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PuJJ-6JG_pzj",
    "outputId": "ee78259c-7ecd-4e95-aab8-3956f5d3643d"
   },
   "outputs": [],
   "source": [
    "gridxgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "9d376196",
    "outputId": "d45e67f5-fb4c-49e7-b93a-b362bcf80a80"
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': modelXGB.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "display(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58bbd22e",
    "outputId": "0ac1605f-cc1e-40bd-a869-235952716ee4"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Mejores hiperparámetros proporcionados por el usuario\n",
    "best_xgboost_params = {\n",
    "    'gamma': 0.0001,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'n_estimators': 4,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Calcular scale_pos_weight para manejar el desbalance de clases (como se hizo antes)\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "# Instanciar y entrenar el modelo XGBoost con los mejores hiperparámetros\n",
    "final_modelXGB = XGBClassifier(\n",
    "    **best_xgboost_params,\n",
    "    eval_metric='logloss', # Asegurar que se usa una métrica de evaluación adecuada\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "print(\"Entrenando XGBoost con los mejores hiperparámetros...\")\n",
    "final_modelXGB.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n--- Reporte de Clasificación (Conjunto de Entrenamiento) ---\")\n",
    "print(classification_report(y_train, final_modelXGB.predict(X_train)))\n",
    "\n",
    "print(\"\\n--- Reporte de Clasificación (Conjunto de Prueba) ---\")\n",
    "print(classification_report(y_test, final_modelXGB.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "1LvZXhb9PyFX",
    "outputId": "6ae16872-2d5f-4e29-c374-adaa7ccf3920"
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_importance(final_modelXGB, max_num_features=10, importance_type='weight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "3W3LiEVaQSb6",
    "outputId": "e0e78435-dfbb-47d9-dbf6-cea13184ce92"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(final_modelXGB, X_train, y_train, cmap='Blues', normalize='true')\n",
    "ConfusionMatrixDisplay.from_estimator(final_modelXGB, X_test, y_test, cmap='Blues', normalize='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "id": "jKJbkW6uTWh1",
    "outputId": "ad96c8ba-90d0-45a8-fd51-27b5a85ad167"
   },
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(final_modelXGB, X_train, y_train)\n",
    "RocCurveDisplay.from_estimator(final_modelXGB, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CRwuA7xDegK"
   },
   "source": [
    "# Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XtCkdF-DfwV"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "\n",
    "def train_svm_classifier(X_train, y_train, X_test, y_test, random_state=42):\n",
    "    \"\"\"\n",
    "    Entrena un SVM (SVC) con GridSearchCV usando recall.\n",
    "    Retorna el mejor modelo, recall en train/test y el grid.\n",
    "    \"\"\"\n",
    "\n",
    "    # Espacio de búsqueda de hiperparámetros\n",
    "    param_grid = {\n",
    "        \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
    "        \"C\": [0.1, 1, 5, 10],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "        \"degree\": [2, 3, 4]  # solo aplica para poly\n",
    "    }\n",
    "\n",
    "    svm = SVC(class_weight=\"balanced\", probability=False, random_state=random_state)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        svm,\n",
    "        param_grid,\n",
    "        scoring=\"recall\",   # misma métrica que tu RF\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # Predicciones en numpy\n",
    "    y_train_pred = best_model.predict(X_train).astype(np.int32)\n",
    "    y_test_pred  = best_model.predict(X_test ).astype(np.int32)\n",
    "\n",
    "    # Métricas\n",
    "    train_rec = recall_score(y_train, y_train_pred)\n",
    "    test_rec  = recall_score(y_test, y_test_pred)\n",
    "\n",
    "    return best_model, train_rec, test_rec, grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TSd1NtVbDhMZ",
    "outputId": "77533026-65ee-4cd0-bbf2-2645420a8070"
   },
   "outputs": [],
   "source": [
    "modelSVM, train_rec, test_rec, gridSVM = train_svm_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icqJzLaNCHGI",
    "outputId": "fe57398d-9789-45d2-da6f-fcbc18b081df"
   },
   "outputs": [],
   "source": [
    "print(f\"Train recall: {train_rec:.3f}, Test recall: {test_rec:.3f}\")\n",
    "print(gridSVM.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "id": "f18c010a",
    "outputId": "89b90cce-db9d-44d1-e9b0-4510b6f2730d"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Mejores hiperparámetros proporcionados por el usuario para SVM\n",
    "best_svm_params = {\n",
    "    'C': 0.1,\n",
    "    'degree': 4,\n",
    "    'gamma': 'auto',\n",
    "    'kernel': 'poly',\n",
    "    'random_state': 42,\n",
    "    'probability': False # 'probability' needs to be False for predict to work directly without issues if not fitted with it.\n",
    "}\n",
    "\n",
    "# Instanciar y entrenar el modelo SVM con los mejores hiperparámetros\n",
    "# Aseguramos class_weight='balanced' para manejar el desbalance de clases\n",
    "final_modelSVM = SVC(\n",
    "    **best_svm_params,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "print(\"Entrenando SVM con los mejores hiperparámetros...\")\n",
    "final_modelSVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1VJvS4HQQo9",
    "outputId": "56ae37de-8986-4dab-97ca-3b7a33a063b0"
   },
   "outputs": [],
   "source": [
    "print(\"Report for training:\", classification_report(y_train, final_modelSVM.predict(X_train)))\n",
    "print(\"Report for test:\", classification_report(y_test, final_modelSVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "XMiqHl8CEWxC",
    "outputId": "d5f1e4ce-0d46-4c87-81d9-a407b1ecb55d"
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(final_modelSVM, X_train, y_train, cmap='Blues', normalize='true')\n",
    "ConfusionMatrixDisplay.from_estimator(final_modelSVM, X_test, y_test, cmap='Blues', normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "id": "SFPgqmS1CLG4",
    "outputId": "3f72a50b-a8b5-4b8d-96fa-e910671559d2"
   },
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(final_modelSVM, X_train, y_train)\n",
    "RocCurveDisplay.from_estimator(final_modelSVM, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yIWqIwSDgxs"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0M3ORwoTmuS"
   },
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qN0PKLUkfy15"
   },
   "outputs": [],
   "source": [
    "def train_nn_with_tqdm_gs(X, y, device=\"cpu\"):\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    import numpy as np\n",
    "    from sklearn.base import BaseEstimator\n",
    "    from sklearn.metrics import recall_score\n",
    "\n",
    "    # -----------------\n",
    "    # Param grid\n",
    "    # -----------------\n",
    "    param_grid = {\n",
    "        \"hidden_sizes\": [(64, 32), (32, 16), (128, 64, 32)],\n",
    "        \"lr\": [0.0005, 0.0001],\n",
    "        \"epochs\": [50, 100],\n",
    "        \"batch_size\": [32, 64, 128],\n",
    "    }\n",
    "\n",
    "    # -----------------\n",
    "    # Train/Val split\n",
    "    # -----------------\n",
    "    n = len(X)\n",
    "    cut = int(n * 0.8)\n",
    "\n",
    "    X_train = np.asarray(X[:cut], dtype=np.float32)\n",
    "    y_train = np.asarray(y[:cut], dtype=np.float32)\n",
    "\n",
    "    X_val = np.asarray(X[cut:], dtype=np.float32)\n",
    "    y_val = np.asarray(y[cut:], dtype=np.float32)\n",
    "\n",
    "    # -----------------------\n",
    "    # INTERNAL ESTIMATOR\n",
    "    # (scikit-learn compatible)\n",
    "    # -----------------------\n",
    "    class TorchEstimator(BaseEstimator):\n",
    "        def __init__(self, hidden_sizes=(32,16), lr=0.001, epochs=30, batch_size=32):\n",
    "            self.hidden_sizes = hidden_sizes\n",
    "            self.lr = lr\n",
    "            self.epochs = epochs\n",
    "            self.batch_size = batch_size\n",
    "            self.model_ = None\n",
    "\n",
    "        def fit(self, Xf, yf):\n",
    "            Xf = torch.tensor(Xf, dtype=torch.float32).to(device)\n",
    "            yf = torch.tensor(yf, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "            layers = []\n",
    "            inp = Xf.shape[1]\n",
    "            for h in self.hidden_sizes:\n",
    "                layers.append(nn.Linear(inp, h))\n",
    "                layers.append(nn.ReLU())\n",
    "                inp = h\n",
    "            layers.append(nn.Linear(inp, 1))\n",
    "\n",
    "            self.model_ = nn.Sequential(*layers).to(device)\n",
    "\n",
    "            # class weight\n",
    "            pos = yf.sum()\n",
    "            neg = len(yf) - pos\n",
    "            pos_weight = torch.tensor(neg / pos, dtype=torch.float32).to(device)\n",
    "\n",
    "            loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "            opt = optim.Adam(self.model_.parameters(), lr=self.lr)\n",
    "\n",
    "            loader = torch.utils.data.DataLoader(\n",
    "                torch.utils.data.TensorDataset(Xf, yf),\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True\n",
    "            )\n",
    "\n",
    "            for _ in range(self.epochs):\n",
    "                self.model_.train()\n",
    "                for xb, yb in loader:\n",
    "                    opt.zero_grad()\n",
    "                    out = self.model_(xb)\n",
    "                    loss = loss_fn(out, yb)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "\n",
    "            return self\n",
    "\n",
    "        def predict(self, Xp):\n",
    "            Xp = torch.tensor(Xp, dtype=torch.float32).to(device)\n",
    "            self.model_.eval()\n",
    "            with torch.no_grad():\n",
    "                out = torch.sigmoid(self.model_(Xp)).cpu().numpy()\n",
    "            return (out >= 0.5).astype(int)\n",
    "\n",
    "    # -----------------------\n",
    "    # Run TQDM Grid Search\n",
    "    # -----------------------\n",
    "    gs = TQDMGridSearch(\n",
    "        estimator=TorchEstimator(),\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"recall\",\n",
    "        cv=2\n",
    "    )\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # best estimator\n",
    "    best_model = gs.best_estimator_\n",
    "\n",
    "    # eval on val\n",
    "    preds = best_model.predict(X_val)\n",
    "    train_score = recall_score(y_train, best_model.predict(X_train))\n",
    "    test_score = recall_score(y_val, preds)\n",
    "\n",
    "    return best_model, gs, train_score, test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2c5cd6ccaf5448b7838760e8ba810ddc",
      "553289cd7aed48c78c8b512c90addfa4",
      "a8da17126b3640418dc6141b3a124501",
      "b963613e40564ef79045978dc2cb730d",
      "8f17bedc44274f5eb997e5094f31b5c1",
      "1edd609ba1f942d38afd3bd7cb89955b",
      "8f927140a39743c0af562fe756676d0f",
      "57c90b5cc9814b7f914365870f767182",
      "6e1df020c6e64ad984039917a7210ad6",
      "408de9320fa7456a80a6c25a2769c421",
      "b52a7b53d5fd4e59a45033699a03727f"
     ]
    },
    "id": "TwD0dA7Eq50_",
    "outputId": "07b0ffab-f594-439f-8bcc-0a6faabe2426"
   },
   "outputs": [],
   "source": [
    "modelNN, gridnn, train_rec, test_rec = train_nn_with_tqdm_gs(X_train, y_train, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cs4OZO4hqSal"
   },
   "outputs": [],
   "source": [
    "print(f\"Best params: {gridnn.best_params_}\", \"Train recall:\", train_rec, \"Test recall:\", test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HLaoimZTpzF"
   },
   "outputs": [],
   "source": [
    "# model, train_acc, test_acc = train_nn_with_tqdm(X_train, y_train, X_test, y_test, device='cuda')\n",
    "# print(f\"Train accuracy: {train_acc:.3f}, Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oQQ5nSqhVApy",
    "outputId": "8640381a-bba8-4711-a1ca-b41c120ab57f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, RocCurveDisplay, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Detect device of trained model\n",
    "device = next(modelNN.model_.parameters()).device\n",
    "\n",
    "# Ensure numeric\n",
    "X_train_numeric = X_train.astype('float32')\n",
    "X_test_numeric = X_test.astype('float32')\n",
    "\n",
    "# Convert to tensor ON THE SAME DEVICE\n",
    "X_train_t = torch.tensor(X_train_numeric.values, dtype=torch.float32).to(device)\n",
    "X_test_t = torch.tensor(X_test_numeric.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Predictions\n",
    "modelNN.model_.eval()\n",
    "with torch.no_grad():\n",
    "    logits_train = modelNN.model_(X_train_t)\n",
    "    probs_train  = torch.sigmoid(logits_train).cpu().numpy()\n",
    "    logits_test = modelNN.model_(X_test_t)\n",
    "    probs_test  = torch.sigmoid(logits_test).cpu().numpy()\n",
    "    y_train_pred = (probs_train >= 0.5).astype(int)\n",
    "    y_test_pred = (probs_test >= 0.5).astype(int)\n",
    "\n",
    "print(\"Report for training:\", classification_report(y_train, y_train_pred))\n",
    "print(\"Report for test:\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_train = confusion_matrix(y_train, y_train_pred, normalize='true')\n",
    "cm_test = confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "ConfusionMatrixDisplay(cm_train).plot(cmap='Blues')\n",
    "ConfusionMatrixDisplay(cm_test).plot(cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, probs_train)\n",
    "roc_auc_train = roc_auc_score(y_train, probs_train)\n",
    "RocCurveDisplay(fpr=fpr_train, tpr=tpr_train).plot()\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.title(f'ROC Curve (AUC = {roc_auc_train:.3f})')\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, probs_test)\n",
    "roc_auc = roc_auc_score(y_test, probs_test)\n",
    "RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.title(f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDBqMliTezA0"
   },
   "source": [
    "# PCA Y UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2065bf66",
    "outputId": "2a0b7ba3-40e5-4731-f886-57d71e254ca8"
   },
   "outputs": [],
   "source": [
    "# === : MI (OHE) + Pearson + gráficos simples ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Requerimientos\n",
    "if 'df' not in globals():\n",
    "    raise RuntimeError(\"No encuentro 'df' en el notebook.\")\n",
    "if 'X_train' not in globals() or 'y_train' not in globals():\n",
    "    raise RuntimeError(\"No encuentro X_train y/o y_train.\")\n",
    "\n",
    "df_original = df.copy()\n",
    "target_col = 'Churn'\n",
    "\n",
    "# --- 1) One-hot encoding ---\n",
    "df_feats = df_original.drop(columns=[target_col], errors='ignore')\n",
    "df_ohe = pd.get_dummies(df_feats, drop_first=False).fillna(0)\n",
    "\n",
    "# --- 2) Target ---\n",
    "y_full = LabelEncoder().fit_transform(df_original[target_col].astype(str))\n",
    "\n",
    "# --- 3) MI en columnas OHE ---\n",
    "mi_vals = mutual_info_classif(df_ohe.values, y_full, discrete_features='auto', random_state=42)\n",
    "mi_ohe = pd.Series(mi_vals, index=df_ohe.columns).sort_values(ascending=False)\n",
    "\n",
    "# --- 4) Agrupar MI por feature original ---\n",
    "orig_feats = df_feats.columns.tolist()\n",
    "group_map = {}\n",
    "\n",
    "for ohe_col in df_ohe.columns:\n",
    "    matched = None\n",
    "    for orig in orig_feats:\n",
    "        if ohe_col == orig or ohe_col.startswith(orig + \"_\"):\n",
    "            matched = orig\n",
    "            break\n",
    "    if matched is None:\n",
    "        matched = ohe_col.split('_')[0]\n",
    "    group_map.setdefault(matched, []).append(ohe_col)\n",
    "\n",
    "mi_agg = {orig: float(mi_ohe.loc[members].max()) for orig, members in group_map.items()}\n",
    "mi_series = pd.Series(mi_agg).sort_values(ascending=False)\n",
    "\n",
    "# --- 5) Pearson: corregimos SeniorCitizen ---\n",
    "num_cols = [c for c in df_original.columns if pd.api.types.is_numeric_dtype(df_original[c]) and c != target_col]\n",
    "\n",
    "# Excluir SeniorCitizen por ser variable binaria categórica\n",
    "if \"SeniorCitizen\" in num_cols:\n",
    "    num_cols.remove(\"SeniorCitizen\")\n",
    "\n",
    "pearson = {}\n",
    "y_enc = y_full\n",
    "\n",
    "for c in num_cols:\n",
    "    tmp = df_original[[c]].join(pd.Series(y_enc, index=df_original.index, name='target')).dropna()\n",
    "    if tmp.shape[0] > 2:\n",
    "        try:\n",
    "            corr = np.corrcoef(tmp[c].astype(float), tmp['target'].astype(float))[0,1]\n",
    "        except:\n",
    "            corr = np.nan\n",
    "    else:\n",
    "        corr = np.nan\n",
    "    pearson[c] = corr\n",
    "\n",
    "pearson_ser = pd.Series(pearson).sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "\n",
    "# --- 6) Gráficas ---\n",
    "print(\"=== MI aggregated (top 20) ===\")\n",
    "display(mi_series.head(20))\n",
    "mi_series.head(20).plot(kind='bar', figsize=(10,4))\n",
    "plt.ylabel(\"Mutual Information\")\n",
    "plt.title(\"MI (orig features) - top 20\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== Pearson (numeric features) ===\")\n",
    "display(pearson_ser)\n",
    "pearson_ser.plot(kind='bar', figsize=(8,4))\n",
    "plt.title(\"Pearson correlation (numeric only, SeniorCitizen excluido)\")\n",
    "plt.ylabel(\"Pearson r\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 7) Candidatos ---\n",
    "mi_threshold = 0.005\n",
    "pearson_threshold = 0.10\n",
    "\n",
    "candidates = []\n",
    "for feat, val in mi_series.items():\n",
    "    if val < mi_threshold:\n",
    "        candidates.append(feat)\n",
    "\n",
    "for feat, val in pearson_ser.items():\n",
    "    if pd.notna(val) and abs(val) < pearson_threshold and feat not in candidates:\n",
    "        candidates.append(feat)\n",
    "\n",
    "print(f\"Candidatos (según MI < {mi_threshold} o |Pearson| < {pearson_threshold}):\")\n",
    "print(candidates)\n",
    "\n",
    "# --- Guardar ---\n",
    "mi_series.to_csv(\"mi_per_feature_orig_minimal.csv\")\n",
    "pearson_ser.to_csv(\"pearson_numeric_minimal.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "56906ad9",
    "outputId": "10eee22f-a654-4f63-c515-ec8294cba9a9"
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 5.2 PCA + evaluación de modelos (XGBoost + SVM)\n",
    "# -------------------------\n",
    "print(\"\\n-- 5.2 PCA y evaluación (XGBoost + SVM) --\")\n",
    "\n",
    "# Imports requeridos\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Validar modelos entrenados\n",
    "if 'final_modelXGB' not in globals() or 'final_modelSVM' not in globals():\n",
    "    raise RuntimeError(\"final_modelXGB o final_modelSVM no están definidos. Ejecuta las celdas de entrenamiento.\")\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": final_modelXGB,\n",
    "    \"SVM\": final_modelSVM\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# evaluación en espacio original (X_train)\n",
    "X_for_analysis = X_train.copy()\n",
    "y_for_analysis = y_train.copy()\n",
    "\n",
    "base_results = {}\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        scores = cross_val_score(model,\n",
    "                                 X_for_analysis,\n",
    "                                 y_for_analysis,\n",
    "                                 cv=cv,\n",
    "                                 scoring=\"recall\",\n",
    "                                 n_jobs=-1)\n",
    "        base_results[name] = {\n",
    "            \"mean_recall\": float(np.mean(scores)),\n",
    "            \"std\": float(np.std(scores))\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluando {name} en espacio original: {e}\")\n",
    "        base_results[name] = {\"mean_recall\": np.nan, \"std\": np.nan}\n",
    "\n",
    "    print(f\"{name} (base): mean Recall = {base_results[name]['mean_recall']:.4f} ± {base_results[name]['std']:.4f}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# PCA (95% varianza explicada)\n",
    "# -------------------------\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_for_analysis)\n",
    "explained = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "\n",
    "def choose_n_by_variance(threshold=0.95):\n",
    "    idx = np.searchsorted(explained, threshold) + 1\n",
    "    return min(idx, X_for_analysis.shape[1]-1)\n",
    "\n",
    "n_pca = choose_n_by_variance(0.95)\n",
    "\n",
    "print(f\"PCA -> n_components = {n_pca} (95% varianza acumulada). \"\n",
    "      f\"Reducción% = {100*(1 - n_pca / X_for_analysis.shape[1]):.1f}%\")\n",
    "\n",
    "pca = PCA(n_components=n_pca)\n",
    "X_pca = pca.fit_transform(X_for_analysis)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Evaluación con PCA\n",
    "# -------------------------\n",
    "pca_results = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model,\n",
    "                             X_pca,\n",
    "                             y_for_analysis,\n",
    "                             cv=cv,\n",
    "                             scoring=\"recall\",\n",
    "                             n_jobs=-1)\n",
    "    pca_results[name] = {\n",
    "        \"mean_recall\": float(np.mean(scores)),\n",
    "        \"std\": float(np.std(scores))\n",
    "    }\n",
    "\n",
    "    print(f\"{name} (PCA): mean Recall = {pca_results[name]['mean_recall']:.4f} ± {pca_results[name]['std']:.4f}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Tabla de resultados PCA\n",
    "# -------------------------\n",
    "pca_table = pd.DataFrame([\n",
    "    {\n",
    "        \"model\": name,\n",
    "        \"mean_recall\": v[\"mean_recall\"],\n",
    "        \"std_recall\": v[\"std\"],\n",
    "        \"n_components\": n_pca,\n",
    "        \"reduction_pct\": 100*(1 - n_pca/X_for_analysis.shape[1])\n",
    "    }\n",
    "    for name, v in pca_results.items()\n",
    "])\n",
    "\n",
    "display(pca_table)\n",
    "pca_table.to_csv(\"pca_results.csv\", index=False)\n",
    "print(\"Guardado: pca_results.csv (Recall).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3k4FSCfOijA",
    "outputId": "3f504844-09d4-47bd-d361-1fce856d9f8a"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio torchtext\n",
    "!pip uninstall -y nvidia-cublas-cu12 nvidia-cuda-nvrtc-cu12 nvidia-cufft-cu12 \\\n",
    "                 nvidia-curand-cu12 nvidia-cusolver-cu12 nvidia-cusparse-cu12 \\\n",
    "                 nvidia-nvjitlink-cu12\n",
    "!pip install -q --extra-index-url=https://pypi.nvidia.com cuml-cu12\n",
    "\n",
    "from cuml.manifold import UMAP as UMAP_GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363,
     "referenced_widgets": [
      "9f06e9d21602415298a16db67ba6923c",
      "31d6a63b1f7a4d11bb65c1d62b9f98c6",
      "1ba814f1e3654114b6be23f29a4cc65d",
      "a4d74170a7054e91a7147c21c13078f3",
      "2ca704844e474c29a6387fba691bfb6c",
      "6f2df28c9ecb4ada96e78808e8805361",
      "429f3ff1f33347899254bb07448a1ca4",
      "c535732aac324423a85b8e69e561049f",
      "ee28e2a9aa8d403f95493f7a7f34392a",
      "2d1e471055a44096a96f581ccfd7d67d",
      "fb92d7fe8c9e46a5bae05aba3f60278a"
     ]
    },
    "id": "6b849b49",
    "outputId": "a4eecc8e-0e51-4709-9ca9-eccbc65a0c84"
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 5.3 UMAP GPU – Versión final optimizada para clasificación\n",
    "# ===============================================================\n",
    "\n",
    "from cuml.manifold import UMAP as UMAP_GPU\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "print(\"✓ Ejecutando UMAP GPU optimizado (sin PCA)…\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# CONFIGURACIÓN\n",
    "# ----------------------------------------------------------------\n",
    "umap_dims = [3, 5, 10, 15]       # Dimensiones recomendadas\n",
    "n_neighbors = 50                 # Más información global → mejor SVM\n",
    "min_dist = 0.1                   # Separación suave entre clusters\n",
    "n_epochs = 500                   # Más convergencia\n",
    "\n",
    "\n",
    "build_algo = \"nn_descent\"        # Rápido y 100% compatible cuML (NO ivfflat)\n",
    "\n",
    "sample_frac = 1.0                # Usar TODO el dataset\n",
    "cv_folds = 5\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# MUESTRA\n",
    "# ----------------------------------------------------------------\n",
    "n_sample = int(len(X_train) * sample_frac)\n",
    "idx = np.random.choice(len(X_train), n_sample, replace=False)\n",
    "\n",
    "X_s = X_train.iloc[idx].values      # Arrays → más rápido para cuML\n",
    "y_s = np.array(y_train)[idx]\n",
    "\n",
    "print(f\"Usando {n_sample} filas ({sample_frac*100:.0f}%).\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# VALIDACIÓN\n",
    "# ----------------------------------------------------------------\n",
    "cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Ejecutando UMAP GPU…\\n\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# LOOP UMAP\n",
    "# ----------------------------------------------------------------\n",
    "for d in tqdm(umap_dims):\n",
    "\n",
    "    reducer = UMAP_GPU(\n",
    "        n_components=d,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_epochs=n_epochs,\n",
    "        init=\"spectral\",\n",
    "        random_state=None,          # Mantener para activar GPU\n",
    "        build_algo=build_algo       # ← AQUÍ USAMOS nn_descent\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # ---- Reducir dimensionalidad con UMAP GPU ----\n",
    "    X_um = reducer.fit_transform(X_s)\n",
    "\n",
    "    row = {\"n_components\": d}\n",
    "\n",
    "    # ---- Evaluación Recall (XGBoost y SVM) ----\n",
    "    for name, model in {\n",
    "        \"XGBoost\": final_modelXGB,\n",
    "        \"SVM\": final_modelSVM\n",
    "    }.items():\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model, X_um, y_s,\n",
    "            cv=cv, scoring=\"recall\", n_jobs=-1\n",
    "        )\n",
    "\n",
    "        row[f\"{name}_mean_recall\"] = float(scores.mean())\n",
    "        row[f\"{name}_std\"] = float(scores.std())\n",
    "\n",
    "    row[\"time_s\"] = time.time() - t0\n",
    "    results.append(row)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# RESULTADOS\n",
    "# ----------------------------------------------------------------\n",
    "umap_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nResultados finales UMAP GPU (optimizado):\")\n",
    "display(umap_df)\n",
    "\n",
    "umap_df.to_csv(\"umap_results_gpu_optimized.csv\", index=False)\n",
    "print(\"\\nGuardado: umap_results_gpu_optimized.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPELxqMAeYD5"
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Gráfico UMAP 3D (Plotly interactivo)\n",
    "# ===============================================================\n",
    "\n",
    "from cuml.manifold import UMAP as UMAP_GPU\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "print(\"✓ Generando embedding UMAP 3D para visualización…\")\n",
    "\n",
    "# Parámetros del mejor modelo visual\n",
    "d = 3\n",
    "n_neighbors = 50\n",
    "min_dist = 0.1\n",
    "n_epochs = 500\n",
    "\n",
    "# Usamos TODO el dataset (X_s y y_s)\n",
    "X_array = X_train.values\n",
    "y_array = np.array(y_train)\n",
    "\n",
    "# Reducir a 3 dimensiones con UMAP GPU\n",
    "reducer_3d = UMAP_GPU(\n",
    "    n_components=3,\n",
    "    n_neighbors=n_neighbors,\n",
    "    min_dist=min_dist,\n",
    "    n_epochs=n_epochs,\n",
    "    init=\"spectral\",\n",
    "    random_state=42,\n",
    "    build_algo=\"nn_descent\"\n",
    ")\n",
    "\n",
    "X_um_3d = reducer_3d.fit_transform(X_array)\n",
    "\n",
    "print(\"✓ UMAP 3D generado.\")\n",
    "\n",
    "# Construir DataFrame para graficar\n",
    "df_umap3d = pd.DataFrame({\n",
    "    \"UMAP1\": X_um_3d[:,0],\n",
    "    \"UMAP2\": X_um_3d[:,1],\n",
    "    \"UMAP3\": X_um_3d[:,2],\n",
    "    \"Churn\": y_array.astype(int)\n",
    "})\n",
    "\n",
    "# Gráfico interactivo 3D (Plotly)\n",
    "fig = px.scatter_3d(\n",
    "    df_umap3d,\n",
    "    x=\"UMAP1\", y=\"UMAP2\", z=\"UMAP3\",\n",
    "    color=\"Churn\",\n",
    "    title=\"UMAP en 3 dimensiones (GPU)\",\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvMWp9v9gfsy"
   },
   "outputs": [],
   "source": [
    "# Requiere: X_um_3d (n x 3 embedding) o recalcular UMAP 3D si no existe.\n",
    "# También requiere X_train (DataFrame) y df original con columnas como 'tenure', 'MonthlyCharges', 'Contract'.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Opción A: si ya tienes X_um_3d en memoria (embedding 3D)\n",
    "# X_um_3d = ...  # numpy array shape (n,3)\n",
    "\n",
    "# Opción B: recalcular (si no tienes X_um_3d). Usa tu UMAP GPU o cuML\n",
    "# from cuml.manifold import UMAP as UMAP_GPU\n",
    "# reducer = UMAP_GPU(n_components=3, n_neighbors=50, min_dist=0.1, n_epochs=500,\n",
    "#                    init=\"spectral\", random_state=42, build_algo=\"nn_descent\")\n",
    "# X_um_3d = reducer.fit_transform(X_train.values)   # demora según tamaño\n",
    "\n",
    "# Usar X_um_3d aquí:\n",
    "df_vis = pd.DataFrame({\n",
    "    \"UMAP1\": X_um_3d[:,0],\n",
    "    \"UMAP2\": X_um_3d[:,1],\n",
    "    \"UMAP3\": X_um_3d[:,2],\n",
    "    \"Churn\": np.array(y_train).astype(int)   # o y_s si usaste muestra\n",
    "})\n",
    "\n",
    "# Añade columnas útiles del df original para hover (asegúrate de que índices correspondan)\n",
    "# por ejemplo, si df_original tiene las columnas:\n",
    "cols_to_add = ['tenure','MonthlyCharges','TotalCharges','Contract']  # ajusta nombres reales\n",
    "for c in cols_to_add:\n",
    "    if c in df.columns:\n",
    "        df_vis[c] = df[c].iloc[df_vis.index].values   # o usa X_train.index si es distinto\n",
    "\n",
    "# Gráfico interactivo 3D con hover\n",
    "fig = px.scatter_3d(df_vis,\n",
    "                    x='UMAP1', y='UMAP2', z='UMAP3',\n",
    "                    color='Churn',\n",
    "                    hover_data=cols_to_add,   # muestra esas variables en tooltip\n",
    "                    title='UMAP 3D (coloreado por Churn, hover con variables clave)',\n",
    "                    opacity=0.8,\n",
    "                    width=900, height=600)\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Wit2E0nkM3gp"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
